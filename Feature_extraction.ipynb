{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SujaaShri/Product-Feature-Extractor/blob/main/Feature_extraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C8lQkkeehPjS"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from collections import defaultdict, Counter\n",
        "from transformers import pipeline, AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('punkt')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pONEUcbdfvCg"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "# Load CSV with expected columns: 'productId', 'Title', 'Text'\n",
        "df = pd.read_csv(next(iter(uploaded)))\n",
        "df = df[['productId', 'Title', 'Text']].dropna()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1d6Ghtsyf2Zp"
      },
      "outputs": [],
      "source": [
        "def split_into_sentences(review):\n",
        "    return sent_tokenize(review)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pYozpm54f5SF"
      },
      "outputs": [],
      "source": [
        "sentiment_analyzer = pipeline(\"sentiment-analysis\")\n",
        "\n",
        "def get_sentiment(sentences):\n",
        "    pos, neg = [], []\n",
        "    for sentence in sentences:\n",
        "        result = sentiment_analyzer(sentence)[0]\n",
        "        label = result['label'].lower()\n",
        "        if label == 'positive':\n",
        "            pos.append(sentence)\n",
        "        elif label == 'negative':\n",
        "            neg.append(sentence)\n",
        "    return pos, neg\n",
        "\n",
        "df[['pos_sents', 'neg_sents']] = df['Text'].apply(\n",
        "    lambda x: pd.Series(get_sentiment(split_into_sentences(x)))\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZT3XBje_f8yI"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-base\")\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-base\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KfydwJTegSZK"
      },
      "outputs": [],
      "source": [
        "def extract_features(sentences):\n",
        "    features = []\n",
        "    for sentence in sentences:\n",
        "        prompt = f\"\"\"Extract only product features (like 'battery life', 'design', 'price', etc.) mentioned in the following sentence. Do not include opinions or full sentences.\n",
        "\n",
        "Sentence: \"{sentence}\"\n",
        "\n",
        "Features:\"\"\"\n",
        "        inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True)\n",
        "        outputs = model.generate(**inputs, max_length=64)\n",
        "        result = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "        features += [f.strip().lower() for f in result.split(',') if f.strip()]\n",
        "    return features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4xwKBvRLPBpA"
      },
      "outputs": [],
      "source": [
        "df['pos_features'] = df['pos_sents'].apply(extract_features)\n",
        "df['neg_features'] = df['neg_sents'].apply(extract_features)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FmfScTSrn5p3"
      },
      "outputs": [],
      "source": [
        "summary = defaultdict(lambda: {'title': '', 'pos': [], 'neg': []})\n",
        "\n",
        "for _, row in df.iterrows():\n",
        "    pid = row['productId']\n",
        "    summary[pid]['title'] = row['Title']\n",
        "    summary[pid]['pos'] += row['pos_features']\n",
        "    summary[pid]['neg'] += row['neg_features']\n",
        "\n",
        "for pid, feats in summary.items():\n",
        "    pos_top = [f for f, _ in Counter(feats['pos']).most_common(3)]\n",
        "    neg_top = [f for f, _ in Counter(feats['neg']).most_common(3)]\n",
        "    print(f\"Product: {feats['title']}\")\n",
        "    print(f\"  Most Appreciated Features: {', '.join(pos_top) or 'None'}\")\n",
        "    print(f\"  Least Appreciated Features: {', '.join(neg_top) or 'None'}\\n\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMrCXZT/T32eiHv/5lekxV0",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}